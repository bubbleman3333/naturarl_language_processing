ベクトル化のアプローチは主に二つ
１つはカウントベース、もう一つは推論ベース

これらはともに分布仮説がもとになっている


カウントベースでは、コーパス全体で学習が必要になる、
推論ベースではミニバッチ学習をして逐次的に学習を行うことが出来る


推論ベースの概要

You [?] goodbye and I say hello.

この文章が来た時に、?の中にどのような単語が出現するのかを推論する

最初のステップとして、単語をone-hotで表現する

["a","b"]というように単語ごとにインデックスを割り振っておき、aがきたら
[1,0]というように1のフラグだけ立てておく
コンテクストを2とすれば、入力層は2、つまりone-hotが2つになるようにする

中間層のニューロンの変換後は、h1とh2の平均をとる

o
o
o
o
o
o
        ⇒⇒⇒ o   ←ここで平均をとるイメージ
              o
              o
o
o
o
o
o

スコアにはsoftmaxを適用して、確率を得る。


point⇒中間層のニューロン数を入力層のニューロン数よりも少なくする
こうすることによって、単語を予測することに必要な情報をコンパクトにまとめる

ニューラルネットワークによって学習をすると、コンテキストをうまく学習できるようになっている

